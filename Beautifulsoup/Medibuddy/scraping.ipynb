{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ff357-e415-4e12-a191-5493d9be2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import DictWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedded29-28c8-48b0-9786-f9d873baf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_names = list()\n",
    "\n",
    "with open('/tmp/med_names.txt', 'r') as f:\n",
    "    med_names = f.readlines()\n",
    "\n",
    "\n",
    "def google_search(query, api_key, cx):\n",
    "    base_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"key\": api_key,\n",
    "        \"cx\": cx\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"items\" in data:\n",
    "            search_results = data[\"items\"]\n",
    "            return search_results\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        print(\"Error: Unable to perform the search.\")\n",
    "        return []\n",
    "\n",
    "# Replace these variables with your actual API key and custom search engine ID (cx)\n",
    "api_key = \"AIzaSyDn7Mxf9Jy_Pjvk9i3oNHARh2wjNVdZzkQ\"\n",
    "cx = \"d06be8dbe6a4c4c97\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da2447-c86f-4436-85c0-2da2e1f56612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127f9c9-e1e3-494f-bd16-f0033547273a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_results = dict()\n",
    "for name in med_names:\n",
    "    results = google_search(name, api_key, cx)\n",
    "\n",
    "    if results:\n",
    "        for result in results:\n",
    "            title = result[\"title\"]\n",
    "            link = result[\"link\"]\n",
    "            print(f\"Title: {title}\")\n",
    "            print(f\"Link: {link}\")\n",
    "            print(\"---\")\n",
    "        google_results[name] = results\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447309a4-b683-4e47-973e-daeec8d0c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_site_urls = dict()\n",
    "for name in google_results:\n",
    "    site_urls = dict()\n",
    "    for result in google_results[name]:\n",
    "        if 'pharmeasy'in result['link']:\n",
    "            site_urls['pharmeasy'] = result['link']\n",
    "        elif 'apollopharmacy'in result['link']:\n",
    "            site_urls['apollopharmacy'] = result['link']\n",
    "        elif 'netmeds'in result['link']:\n",
    "            site_urls['netmeds'] = result['link']\n",
    "        elif '1mg'in result['link']:\n",
    "            site_urls['1mg'] = result['link']\n",
    "    keyword_site_urls[name] = site_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea138d7b-fc07-4226-ba3a-9febb996c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_urls_list = list()\n",
    "for keyword in keyword_site_urls:\n",
    "    site_urls_list.append({\n",
    "        'keyword': keyword,\n",
    "        '1mg': keyword_site_urls[keyword].get('1mg', ''),\n",
    "        'netmeds': keyword_site_urls[keyword].get('netmeds', ''),\n",
    "        'apollopharmacy': keyword_site_urls[keyword].get('apollopharmacy', ''),\n",
    "    })\n",
    "\n",
    "f = open('/tmp/keyword_urls.csv', 'w')\n",
    "writer = DictWriter(f, fieldnames = site_urls_list[0].keys())\n",
    "writer.writeheader()\n",
    "writer.writerows(site_urls_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc246a-f594-4844-94de-c313664fe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "onemg_responses = dict()\n",
    "\n",
    "headers = {\n",
    "    'authority': 'www.1mg.com',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'cookie': 'VISITOR-ID=c042f201-ea11-4710-c7f5-680e8b432df4_acce55_1702704046',\n",
    "    'dnt': '1',\n",
    "    'referer': 'https://www.1mg.com/categories/vitamin-supplements/vitamin-d-121',\n",
    "    'sec-ch-ua': '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\", \"Google Chrome\";v=\"120\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "for keyword in keyword_site_urls:\n",
    "    if '1mg' in keyword_site_urls[keyword].keys():\n",
    "        url = keyword_site_urls[keyword]['1mg']\n",
    "        # Sending a GET request to the URL\n",
    "        response = requests.get(url, headers=headers)\n",
    "        # Checking if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            onemg_responses[keyword] = response.text\n",
    "            print(\"HTML content fetched and saved.\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b184ad-b7a4-47d1-b617-e37e8393e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(onemg_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0fa05-1824-4ff2-8fb3-f6a1ba216c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "omemg_data = list()\n",
    "onemg_dict = dict()\n",
    "\n",
    "for keyword in onemg_responses:\n",
    "    print (keyword)\n",
    "    \n",
    "    try:\n",
    "        soup = BeautifulSoup(onemg_responses[keyword], 'html.parser')\n",
    "        \n",
    "        drug_title = soup.find_all('h1', class_=lambda value: value and value.startswith('DrugHeader__title-content'))[0].get_text()\n",
    "        drug_marketer = soup.find_all('div', class_=lambda value: value and value.startswith('DrugHeader__meta-value'))[0].get_text()\n",
    "        salt_info = soup.find_all('div', 'saltInfo')[0].get_text()\n",
    "        salt_synonms = soup.find_all('div', 'saltInfo')[1].get_text()\n",
    "        try:\n",
    "            storage = soup.find_all('div', 'saltInfo')[2].get_text()\n",
    "        except:\n",
    "            storage = salt_synonms\n",
    "            salt_synonms = ''\n",
    "        product_info = soup.find_all('div', class_=lambda value: value and value.startswith('DrugOverview__content'))[0].get_text()\n",
    "        try:\n",
    "            drug_uses_div = soup.find_all('ul', class_=lambda value: value and value.startswith('DrugOverview__list'))[0]\n",
    "            drug_uses = '\\n'.join(para.get_text() for para in drug_uses_div.find_all('li'))\n",
    "            drug_benefits_children = soup.find_all('div', class_=lambda value: value and value.startswith('ShowMoreArray__tile'))[0]\n",
    "\n",
    "            drug_benefits_div = drug_benefits_children.children\n",
    "            drug_benefits = ''\n",
    "            for child in drug_benefits_div:\n",
    "                benefit = child.get_text()\n",
    "                if benefit:\n",
    "                    drug_benefits += benefit + '\\n\\n'\n",
    "        except:\n",
    "            drug_uses = ''\n",
    "            drug_benefits = ''\n",
    "        \n",
    "        try:\n",
    "            side_effects_div = soup.find('div', id='side_effects')\n",
    "            side_effects_text = side_effects_div.find_all('div', class_=lambda value: value and value.startswith('DrugOverview__content'))[0].get_text()\n",
    "            side_effects_list_div = side_effects_div.find_all('div', class_=lambda value: value and value.startswith('DrugOverview__content'))[1]\n",
    "            side_effects_list = '\\n'.join(para.get_text() for para in side_effects_list_div.find_all('li'))\n",
    "        except:\n",
    "            side_effects_text = ''\n",
    "            side_effects_list = ''\n",
    "            \n",
    "        how_to_use = soup.find('div', id='how_to_use').get_text()\n",
    "        how_drug_works = soup.find('div', id='how_drug_works').get_text()\n",
    "        \n",
    "        safety_advice_div = soup.find('div', id='safety_advice').find_all('div', class_=lambda value: value and value.startswith('DrugOverview__content'))[0]\n",
    "        drug_overview_warnings_div = safety_advice_div.find_all('div', class_=lambda value: value and value.startswith('DrugOverview__warning-top'))\n",
    "        drug_warnings_descs = safety_advice_div.find_all('div', class_=lambda value: value and value.startswith('DrugOverview__content'))\n",
    "        \n",
    "        safety_advice = ''\n",
    "        for i, warning_div in enumerate(drug_overview_warnings_div):\n",
    "            warning_title = warning_div.find('span').get_text()\n",
    "            warning_tag = warning_div.find('div', class_=lambda value: value and value.startswith('DrugOverview__warning-tag')).get_text()\n",
    "            warning_desc = drug_warnings_descs[i].get_text()\n",
    "            safety_advice += 'Title:'+ warning_title + '\\n' + 'Tag:' + warning_tag + 'Description:' + warning_desc\n",
    "        try:\n",
    "            missed_dose = soup.find('div', id='missed_dose').get_text()\n",
    "        except:\n",
    "            missed_dose = ''\n",
    "        \n",
    "        try:\n",
    "            substitutes_div = soup.find('div', id='substitutes')\n",
    "            substitutes =  substitutes_div.find_all('div', class_=lambda value: value and value.startswith('SubstituteItem__item'))\n",
    "            substitutes_text = ''\n",
    "            for row in substitutes:\n",
    "                sub_name = row.find('div', class_=lambda value: value and value.startswith('SubstituteItem__name')).get_text()\n",
    "                sub_manc_name = row.find('div', class_=lambda value: value and value.startswith('SubstituteItem__manufacturer-name')).get_text()\n",
    "                substitutes_text += 'Substitute Name: '+ sub_name +'\\n Manufacturer Name: '+ sub_manc_name + '\\n\\n'\n",
    "        except:\n",
    "            substitutes_text = ''\n",
    "        \n",
    "        quick_tips_arr = soup.find('div', id='expert_advice').find('ul')\n",
    "        quick_tips = '\\n'.join(para.get_text() for para in quick_tips_arr.find_all('li'))\n",
    "        fact_box_left_arr = soup.find('div', id='fact_box').find_all('div', class_=lambda value: value and value.startswith('DrugFactBox__col-left'))\n",
    "        fact_box_right_arr = soup.find('div', id='fact_box').find_all('div', class_=lambda value: value and value.startswith('DrugFactBox__col-right'))\n",
    "\n",
    "        facts = ''\n",
    "        for i, fact in enumerate(fact_box_left_arr):\n",
    "            fact_tag = fact.get_text()\n",
    "            fact_detail = fact_box_right_arr[i].get_text()\n",
    "            facts += fact_tag + ':' + fact_detail + '\\n'\n",
    "        try:\n",
    "            \n",
    "            drug_interaction = soup.find('div', id='drug_interaction')\n",
    "            drug_interaction_desc = drug_interaction.find_all('div', class_=lambda value: value and value.startswith('DrugInteraction__desc'))\n",
    "            \n",
    "            drug_interaction_content = drug_interaction.find('div', class_=lambda value: value and value.startswith('DrugInteraction__content'))\n",
    "            drug_interaction_rows = drug_interaction_content.find_all('div', class_=lambda value: value and value.startswith('DrugInteraction__row'))\n",
    "\n",
    "            drug_interactions_text = ''\n",
    "            for di_row in drug_interaction_rows:\n",
    "                di_drug = di_row.find('div', class_=lambda value: value and value.startswith('DrugInteraction__drug')).get_text()\n",
    "                di_brands = di_row.find('div', class_=lambda value: value and value.startswith('DrugInteraction__brands')).get_text()\n",
    "                di_interaction = di_row.find('div', class_=lambda value: value and value.startswith('DrugInteraction__interaction')).get_text()\n",
    "                drug_interactions_text += 'Drug:' + di_drug + '\\n Brands:' + di_brands + '\\nInteraction:' + di_interaction + '\\n\\n'\n",
    "        except:\n",
    "            drug_interactions_text = ''\n",
    "        \n",
    "        faq_div = soup.find('div', id='faq')\n",
    "        faq_ques_div = faq_div.find_all('h3', class_=lambda value: value and value.startswith('Faqs__ques'))\n",
    "        faq_ans_div = faq_div.find_all('div', class_=lambda value: value and value.startswith('Faqs__ans'))\n",
    "        faqs = ''\n",
    "        for i, ques_block in enumerate(faq_ques_div):\n",
    "            ques = ques_block.get_text()\n",
    "            ans = faq_ans_div[i].get_text()\n",
    "            faqs += ques + '\\n' + ans + '\\n\\n'\n",
    "        \n",
    "        disclaimer = soup.find('div', class_=lambda value: value and value.startswith('DrugPage__auxiliary')).get_text()\n",
    "        references_div = soup.find('ol', class_=lambda value: value and value.startswith('DrugPage__reference'))\n",
    "        compliance_info =soup.find('div', class_=lambda value: value and value.startswith('DrugPage__compliance-info')).get_text()\n",
    "\n",
    "\n",
    "        onemg_row = {\n",
    "            'keyword': keyword,\n",
    "            'drug_title': drug_title,\n",
    "            'drug_marketer': drug_marketer,\n",
    "            'salt_info': salt_info,\n",
    "            'salt_synonms': salt_synonms,\n",
    "            'storage': storage,\n",
    "            'salt_synonms': salt_synonms,\n",
    "            'product_info': product_info,\n",
    "            'drug_uses':drug_uses,\n",
    "            'drug_benefits': drug_benefits,\n",
    "            'side_effects_text': side_effects_text,\n",
    "            'side_effects_list': side_effects_list,\n",
    "            'how_to_use': how_to_use,\n",
    "            'how_drug_works': how_drug_works,\n",
    "            'safety_advice': safety_advice,\n",
    "            'missed_dose': missed_dose,\n",
    "            'substitutes_text': substitutes_text,\n",
    "            'quick_tips_arr': quick_tips,\n",
    "            'facts': facts,\n",
    "            'drug_interaction_text': drug_interactions_text,\n",
    "            'faqs': faqs,\n",
    "            'disclaimer': disclaimer,\n",
    "            'references_div': references_div,\n",
    "            'compliance_info':compliance_info,\n",
    "            \n",
    "        }\n",
    "        omemg_data.append(onemg_row)\n",
    "        onemg_dict[keyword] = onemg_row\n",
    "        # print (disclaimer)\n",
    "    except Exception as e: \n",
    "        print (e)\n",
    "\n",
    "\n",
    "\n",
    "f = open('/tmp/omemg.csv', 'w')\n",
    "writer = DictWriter(f, fieldnames = omemg_data[0].keys())\n",
    "writer.writeheader()\n",
    "writer.writerows(omemg_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee24cb09-8fcf-426c-8077-a3c467600ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "omemg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671f297-23c0-42dc-8ab3-d23eebf8092b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f116370-59c9-4705-9c99-a0e31ec48e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "apollo_responses = dict()\n",
    "\n",
    "for keyword in keyword_site_urls:\n",
    "    if 'apollopharmacy' in keyword_site_urls[keyword].keys():\n",
    "        url = keyword_site_urls[keyword]['apollopharmacy']\n",
    "        # Sending a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        # Checking if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            apollo_responses[keyword] = response.text\n",
    "            print(\"HTML content fetched and saved.\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f451e99-68b2-4f5e-9a28-8070d2fcfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "apollo_data = list()\n",
    "apollo_dict = dict()\n",
    "for keyword in apollo_responses:\n",
    "    print (keyword)\n",
    "    \n",
    "    # try:\n",
    "    soup = BeautifulSoup(apollo_responses[keyword], 'html.parser')\n",
    "\n",
    "    # images_div =  soup.find('div', class_=lambda value: value and value.startswith('PdpImagePlaceholder_pdpGallery')).find_all('img')\n",
    "    images = ''\n",
    "    # for image in images_div:\n",
    "    #     print (image)\n",
    "    #     src_value = image['src'] if image else None\n",
    "    #     images += src_value + '\\n'\n",
    "    \n",
    "    drug_title = soup.find_all('div', class_=lambda value: value and value.startswith('PdpImagePlaceholder_title'))[0].get_text()\n",
    "    prescription_drug = soup.find_all('div', class_=lambda value: value and value.startswith('PdpImagePlaceholder_pdpTagWrapper'))[0].get_text()\n",
    "    product_info_div = soup.find('div', class_=lambda value: value and value.startswith('PdpImagePlaceholder_productInfoRoot'))\n",
    "    product_info_grids = soup.find_all('div', class_=lambda value: value and value.startswith('Grid_Item'))\n",
    "    manufacturer = product_info_grids[1].get_text()\n",
    "    \n",
    "    product_data = soup.find_all('div', class_='yh')\n",
    "    product_info_blocks = product_data[0].find_all('div', class_='RP')\n",
    "    about = ''\n",
    "    uses = ''\n",
    "    benefits = ''\n",
    "    directions = ''\n",
    "    storage = ''\n",
    "    side_effects = ''\n",
    "    for pi_block in product_info_blocks:\n",
    "        title = pi_block.find('h2').get_text()\n",
    "        desc = '\\n'.join(para.get_text() for para in pi_block.find_all('p'))\n",
    "        if not desc:\n",
    "            desc = '\\n'.join(para.get_text() for para in pi_block.find_all('li'))\n",
    "        if not desc:\n",
    "            desc = pi_block.find('div', class_='VP').get_text()\n",
    "        if 'About' in title:\n",
    "            about = desc\n",
    "        elif 'Uses' in title:\n",
    "            uses = desc\n",
    "        elif 'Benefits' in title:\n",
    "            benefits = desc\n",
    "        elif 'Directions' in title:\n",
    "            directions = desc\n",
    "        elif 'Storage' in title:\n",
    "            storage = desc\n",
    "        elif 'Side Effects' in title:\n",
    "            side_effects = desc\n",
    "    \n",
    "    try:\n",
    "        in_depth_info_blocks = product_data[1].find_all('div', class_='RP')\n",
    "        warnings = ''\n",
    "        interactions_checkers = ''\n",
    "        interactions = ''\n",
    "        habit = ''\n",
    "        diet = ''\n",
    "        advise = ''\n",
    "        for pi_block in in_depth_info_blocks:\n",
    "            title = pi_block.find('h2').get_text()\n",
    "            desc = '\\n'.join(para.get_text() for para in pi_block.find_all('p'))\n",
    "            if not desc:\n",
    "                desc = '\\n'.join(para.get_text() for para in pi_block.find_all('li'))\n",
    "            if not desc:\n",
    "                desc = pi_block.find('div', class_='VP').get_text()\n",
    "            if 'Warnings' in title:\n",
    "                warnings = desc\n",
    "            elif 'Checker' in title:\n",
    "                interactions_checkers = desc\n",
    "            elif 'Interactions' in title:\n",
    "                interactions = desc\n",
    "            elif 'Habit' in title:\n",
    "                habit = desc\n",
    "            elif 'Diet' in title:\n",
    "                diet = desc\n",
    "            elif 'Advise' in title:\n",
    "                advise = desc\n",
    "                \n",
    "    except:\n",
    "        in_depth_info = ''\n",
    "    try:\n",
    "        patients_concern = product_data[2].get_text()\n",
    "    except:\n",
    "        patients_concern = ''\n",
    "\n",
    "    try:\n",
    "        safety_text = ''\n",
    "        safety_data = soup.find('div', class_='bb').find_all('div', class_=\"W_\")\n",
    "        for row in safety_data:\n",
    "            safety_title = row.find('p', class_='Ld').get_text()\n",
    "            safety_tag = row.find('p', class_='_b').get_text()\n",
    "            safety_detail = row.find_all('p', class_='Ld')[1].get_text()\n",
    "            safety_text += 'Title:' + safety_title + '\\n' + 'Tag:' + safety_tag + '\\n' + 'Detail:' + safety_detail + '\\n\\n'\n",
    "        \n",
    "        print (safety_text)\n",
    "    except :\n",
    "        safety_text = ''\n",
    "    \n",
    "    faqs_text = ''\n",
    "    faqs_div = soup.find_all('div', class_='a')\n",
    "    for faq_div in faqs_div:\n",
    "        ques = faq_div.find('div', class_='b').get_text()\n",
    "        ans = faq_div.find('div', class_='g').get_text()\n",
    "        faqs_text += ques + '\\n' + ans + '\\n\\n'\n",
    "    \n",
    "    manufacturer_details = soup.find_all('div', class_='pJ')\n",
    "\n",
    "    apollo_row = {\n",
    "        'images': images,\n",
    "        'drug_title': drug_title,\n",
    "        'prescription_drug': prescription_drug,\n",
    "        'product_info_div': product_info_div,\n",
    "        'product_info_grids': product_info_grids,\n",
    "        'manufacturer': manufacturer,\n",
    "        'about': about,\n",
    "        'uses': uses,\n",
    "        'benefits': benefits,\n",
    "        'directions': directions,\n",
    "        'storage': storage,\n",
    "        'side_effects': side_effects,\n",
    "        'warnings': warnings,\n",
    "        'interactions': interactions,\n",
    "        'interactions_checkers': interactions_checkers,\n",
    "        'habit': habit,\n",
    "        'diet': diet,\n",
    "        'advise': advise,\n",
    "        'patients_concern': patients_concern,\n",
    "        'safety_text': safety_text,\n",
    "        'faqs_text': faqs_text,\n",
    "        'manufacturer_details': manufacturer_details\n",
    "        \n",
    "    }\n",
    "    apollo_data.append(apollo_row)\n",
    "    apollo_dict[keyword] = apollo_row\n",
    "    # break\n",
    "    \n",
    "f = open('/tmp/apollo.csv', 'w')\n",
    "writer = DictWriter(f, fieldnames = apollo_data[0].keys())\n",
    "writer.writeheader()\n",
    "writer.writerows(apollo_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392efebc-3f90-4fea-acc2-c60010d48406",
   "metadata": {},
   "outputs": [],
   "source": [
    "netmed_responses = dict()\n",
    "\n",
    "for keyword in keyword_site_urls:\n",
    "    if 'netmeds' in keyword_site_urls[keyword].keys():\n",
    "        url = keyword_site_urls[keyword]['netmeds']\n",
    "        # Sending a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        # Checking if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            netmed_responses[keyword] = response.text\n",
    "        else:\n",
    "            print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54784a5a-86cb-4baa-b66f-b3442430f955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be696055-079c-410e-83d2-4e03a02328ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "netmeds_data = list()\n",
    "netmeds_dict = dict()\n",
    "\n",
    "def get_li_p_text(block):\n",
    "    block_text = ''\n",
    "    for ddesc in block.children:\n",
    "        if ddesc.name == 'p':\n",
    "            block_text += '\\n' + ddesc.get_text() + '\\n'\n",
    "        elif ddesc.name == 'ul':\n",
    "            block_text += '\\n'.join(para.get_text() for para in ddesc.find_all('li'))\n",
    "        elif ddesc.name == 'table':\n",
    "            table_data = ddesc.find_all('tr')\n",
    "            for i, data_point in enumerate(table_data):\n",
    "                data_point = data_point.get_text()\n",
    "                block_text += data_point + '\\n'\n",
    "    return block_text\n",
    "\n",
    "\n",
    "\n",
    "for keyword in netmed_responses:\n",
    "    print (keyword)\n",
    "    try:\n",
    "        soup = BeautifulSoup(netmed_responses[keyword], 'html.parser')\n",
    "        prod_name = soup.find('div', class_='product-right-block').find('div', class_='prodName').find('h1').get_text()\n",
    "        content = soup.find('div', class_='left-block').find_all('div', class_='inner-content')\n",
    "        for block in content:\n",
    "            block_title = block.find('h2').get_text()\n",
    "            # print (block_title)\n",
    "            if 'INTRODUCTION' in block_title:\n",
    "                introduction = '\\n'.join(para.get_text() for para in block.find_all('p'))\n",
    "            elif 'USES OF' in block_title:\n",
    "                uses_of = '\\n'.join(para.get_text() for para in block.find_all('li'))\n",
    "            elif 'TABLET WORKS' in block_title:\n",
    "                how_it_works = '\\n'.join(para.get_text() for para in block.find_all('p'))\n",
    "            elif 'DIRECTIONS FOR USE' in block_title:\n",
    "                dir_of_use = '\\n'.join(para.get_text() for para in block.find_all('p'))\n",
    "            elif 'UNCOMMON' in block_title:\n",
    "                uncommon_text = get_li_p_text(block)\n",
    "            elif 'COMMON' in block_title:\n",
    "                common_text = get_li_p_text(block)                    \n",
    "            elif 'RARE' in block_title:\n",
    "                rare_text = get_li_p_text(block)\n",
    "            elif 'HOW TO MANAGE' in block_title:\n",
    "                how_to_manage = '\\n'.join(para.get_text() for para in block.find_all('p'))\n",
    "            elif 'WARNING' in block_title:\n",
    "                warning_text = ''\n",
    "                headers = block.find_all('h6')\n",
    "                content = block.find_all('p')\n",
    "                for i, header in enumerate(headers):\n",
    "                    warning_text += header.get_text() + '\\n' + content[i].get_text() + '\\n'\n",
    "                # print(warning_text)\n",
    "            elif 'OTHERS' in block_title:\n",
    "                others_text = get_li_p_text(block)\n",
    "            elif 'INTERACTIONS' in block_title:\n",
    "                interactions = get_li_p_text(block)\n",
    "            elif 'SYNOPSIS' in block_title:\n",
    "                synopsis = get_li_p_text(block)\n",
    "            elif 'MORE INFORMATION' in block_title:\n",
    "                more_info = get_li_p_text(block)\n",
    "            elif 'FAQs' in block_title:\n",
    "                faqs = get_li_p_text(block)\n",
    "            elif 'REFERENCES' in block_title:\n",
    "                references = get_li_p_text(block)\n",
    "            elif 'USEFUL DIAGNOSTIC TESTS' in block_title:\n",
    "                useful_diagnostic_tests = get_li_p_text(block)\n",
    "        \n",
    "        prescript_content_div = soup.find('div', class_='left-block').find_all('div', class_='drug-content')[1].find('div', class_='prescript-txt')\n",
    "        prescript_content_titles = prescript_content_div.find_all('div', class_='manufacturer_name')\n",
    "        prescript_content_titles.extend(prescript_content_div.find_all('div', class_='manufacturer_address'))\n",
    "        prescript_content_data = prescript_content_div.find_all('div', class_='manufacturer__name_value')\n",
    "        prescript_content_data.extend(prescript_content_div.find_all('div', class_='manufacturer_address_value'))\n",
    "        for i,t in enumerate(prescript_content_titles):\n",
    "            continue\n",
    "            # print (t.get_text())\n",
    "            # print (prescript_content_data[i].get_text())\n",
    "        netmeds_row = {\n",
    "            'prod_name': prod_name,\n",
    "            'introduction': introduction,\n",
    "            'uses_of': uses_of,\n",
    "            'how_it_works': how_it_works,\n",
    "            'dir_of_use': dir_of_use,\n",
    "            'uncommon_text': uncommon_text,\n",
    "            'common_text': common_text,\n",
    "            'rare_text': rare_text,\n",
    "            'how_to_manage': how_to_manage,\n",
    "            'warning_text': warning_text,\n",
    "            'others_text': others_text,\n",
    "            'interactions': interactions,\n",
    "            'synopsis': synopsis, \n",
    "            'more_info': more_info,\n",
    "            'faqs':faqs, \n",
    "            'references': references,\n",
    "            'useful_diagnostic_tests': useful_diagnostic_tests\n",
    "        }\n",
    "        netmeds_data.append(netmeds_row)\n",
    "        netmeds_dict[keyword] = netmeds_row\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "\n",
    "\n",
    "f = open('/tmp/netmeds.csv', 'w')\n",
    "writer = DictWriter(f, fieldnames = netmeds_data[0].keys())\n",
    "writer.writeheader()\n",
    "writer.writerows(netmeds_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ede1a0-ce53-469e-96e3-240ed61fac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import AIMessage, FunctionMessage, HumanMessage, SystemMessage\n",
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.llms.base import ChatMessage, MessageRole\n",
    "from llama_index.tools import BaseTool, FunctionTool\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "openai.api_key = \"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\"\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"your_serpapi_api_key\"\n",
    "\n",
    "\n",
    "def get_llm_response(prompt, stop):\n",
    "    response = {'response': None, 'error': None}\n",
    "    # response = {}\n",
    "    if stop:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model='gpt-3.5-turbo',\n",
    "                messages=[\n",
    "                    {'role': 'user', 'content': prompt}\n",
    "                ],\n",
    "                temperature=0.5,\n",
    "                stop=stop\n",
    "            )\n",
    "            response['response'] = completion['choices'][0]['message']['content']\n",
    "        except Exception as e:\n",
    "            response['error'] = str(e)\n",
    "    else:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model='gpt-3.5-turbo',\n",
    "                messages=[\n",
    "                    {'role': 'user', 'content': prompt}\n",
    "                ],\n",
    "                temperature=0.5\n",
    "            )\n",
    "            response['response'] = completion['choices'][0]['message']['content']\n",
    "        except Exception as e:\n",
    "            response['error'] = str(e)\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PrecautionCategory(Enum):\n",
    "    Pregnancy_Conceiving = \"Pregnancy_Conceiving\"\n",
    "    Childrens = \"Childrens\"\n",
    "    Driving = \"Driving\"\n",
    "    Breastfeeding = \"Breastfeeding\"\n",
    "    Periods = \"Periods\"\n",
    "    Infertility = \"Infertility\"\n",
    "    Kidney = \"Kidney\"\n",
    "    Liver = \"Liver\"\n",
    "\n",
    "class Precaution(BaseModel): \n",
    "    \"\"\"Precaution type and detail\"\"\"\n",
    "    precaution_type: str = Field(..., description=\"Type of precaution\")\n",
    "    precaution_detail: str = Field(..., description=\"Detail on the precautions to take\")\n",
    "    \n",
    "# Define the AllPrecautions model\n",
    "class AllPrecautions(BaseModel):\n",
    "    \"\"\"All Precautions\"\"\"\n",
    "    all_precautions: list[Precaution] = Field(..., description=\"all precautions\")\n",
    "\n",
    "\n",
    "keyword_precautions = dict()\n",
    "for keyword in onemg_dict.keys():\n",
    "    \n",
    "    precautions_prompt_tmpl = \"\"\"\n",
    "    Using the information from source1, source2 and source3 write the precaution in detail for mentioned precaution categories.\n",
    "    Give precaution detail for each precaution category and stick to the information provided and facts as this might have legal issues.\n",
    "    Use simple language, easy english and be descriptive to reword the precuation detail, best for SEO and to avoid plagarism.\n",
    "    \n",
    "    Precaution Categories:\n",
    "    Pregnancy_Conceiving, Childrens, Driving, Breastfeeding, Periods, Infertility, Kidney, Liver\n",
    "    \n",
    "    Source1:\n",
    "    {source1}\n",
    "    \n",
    "    Source2:\n",
    "    {source2}\n",
    "    \n",
    "    Source3:\n",
    "    {source3}\n",
    "    \"\"\"\n",
    "    \n",
    "    precautions_prompt = precautions_prompt_tmpl.format(source1=onemg_dict[keyword].get('safety_advice', ''),\n",
    "                                                        source2=apollo_dict.get(keyword, {}).get('safety_text', ''),\n",
    "                                                        source3=netmeds_dict.get(keyword, {}).get('warning_text', ''))\n",
    "    #     print(new_story_prompt)\n",
    "    precautions = get_llm_response(precautions_prompt, '')['response']\n",
    "    keyword_precautions[keyword] = precautions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2baf12d-137e-4725-9adf-1df3ca84a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/tmp/final_med.csv', 'w')\n",
    "data = list()\n",
    "for keyword in keyword_side_effects:\n",
    "    data.append({'keyword': keyword, 'data': keyword_side_effects[keyword]})\n",
    "writer = DictWriter(f, fieldnames = data[0].keys())\n",
    "writer.writeheader()\n",
    "writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4d1bd-b0fb-4e93-b95a-bedc1a3b8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keyword_doctor_consult = dict()\n",
    "doctor_see_prompt_tmpl = \"\"\"\n",
    "We are writing a section 'When to consult doctor' to use  '{keyword}'.\n",
    "Using the relevant information from source1, source2 and source3 write in detail only on 'When to consult doctor' as bullet points.\n",
    "Stick to the information provided and facts as this might have legal issues. Use simple language, easy english, be descriptive and reword to make best for SEO and to avoid plagarism.\n",
    "\n",
    "Source1:\n",
    "{source1}\n",
    "\n",
    "Source2:\n",
    "{source2}\n",
    "\n",
    "When to consult doctor? \n",
    "\"\"\"\n",
    "for keyword in onemg_dict.keys():\n",
    "    see_doctor_prompt = doctor_see_prompt_tmpl.format(keyword=keyword, source1=onemg_dict['NIKORAN 5MG BOTTLE OF 20 TABLETS\\n'].get('safety_advice', ''),\n",
    "                                                        source2=netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('others_text', ''))\n",
    "\n",
    "    see_doctor_text = get_llm_response(see_doctor_prompt, '')['response']\n",
    "    keyword_doctor_consult[keyword] = see_doctor_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68b3d5-bdcf-4666-8849-16fb56ca1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_medicine_interactions = dict()\n",
    "\n",
    "medicine_interactions_prompt_tmpl = \"\"\"\n",
    "We are writing a section 'Medicine Interactions' to use  '{keyword}'.\n",
    "Using the relevant information from source1, source2 and source3 write in detail only on 'Medicine Interactions'.\n",
    "Stick to the information provided and facts as this might have legal issues. Use simple language, easy english, be descriptive and reword to make best for SEO and to avoid plagarism.\n",
    "\n",
    "Source1:\n",
    "{source1}\n",
    "\n",
    "Source2:\n",
    "{source2}\n",
    "\n",
    "Source3:\n",
    "{source3}\n",
    "\n",
    "Medicine Interactions\n",
    "\"\"\"\n",
    "\n",
    "for keyword in onemg_dict.keys():\n",
    "    medicine_interactions_prompt = medicine_interactions_prompt_tmpl.format(keyword=keyword, source1=onemg_dict['NIKORAN 5MG BOTTLE OF 20 TABLETS\\n'].get('drug_interaction_text', ''),\n",
    "                                                                            source2=apollo_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('interactions_checkers', ''),\n",
    "                                                                            source3=netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('interactions', ''))\n",
    "    \n",
    "    medicine_interaction = get_llm_response(medicine_interactions_prompt, '')['response']\n",
    "    keyword_medicine_interactions[keyword] = medicine_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740935c-1c52-4f4f-9f71-e9f56b961099",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a_d_s = dict()\n",
    "f_a_d_prompt_tmpl = \"\"\"\n",
    "We are writing a section 'Interactions with Food, Alcohol & Disease Condidtion' on '{keyword}'.\n",
    "Using only the relevant information for the section from source1, source2 and source3 write in detail on the section.\n",
    "Stick to the information provided and facts as this might have legal issues. Use simple language, easy english, be descriptive and reword to make best for SEO and to avoid plagarism.\n",
    "\n",
    "Source1:\n",
    "{source1}\n",
    "\n",
    "Source2:\n",
    "{source2}\n",
    "\n",
    "Source3:\n",
    "{source3}\n",
    "\n",
    "Interactions with Food:\n",
    "\n",
    "Interactions with Alcohol :\n",
    "\n",
    "Interaction basis Disease Condidtion:\n",
    "\"\"\"\n",
    "\n",
    "for keyword in onemg_dict.keys():\n",
    "    f_a_d_prompt = f_a_d_prompt_tmpl.format(keyword=keyword, source1=onemg_dict['NIKORAN 5MG BOTTLE OF 20 TABLETS\\n'].get('safety_advice', ''),\n",
    "                                                                            source2=apollo_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('interactions', ''),\n",
    "                                                                            source3=netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('warning_text', ''))\n",
    "    \n",
    "    f_a_d = get_llm_response(f_a_d_prompt, 'Other Interactions')['response']\n",
    "    f_a_d_s[keyword] = f_a_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451b07a-4c26-42f7-9555-38657ce76df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_how_to_use = dict()\n",
    "how_to_use_prompt_tmpl = \"\"\"\n",
    "We are writing a section 'How to use?' on '{keyword}'.\n",
    "Using only the relevant information for the section from source1, source2 and source3 write in detail on the section.\n",
    "Stick to the information provided and facts as this might have legal issues. Use simple language, easy english, be descriptive and reword to make best for SEO and to avoid plagarism.\n",
    "\n",
    "Source1:\n",
    "{source1}\n",
    "\n",
    "Source2:\n",
    "{source2}\n",
    "\n",
    "Source3:\n",
    "{source3}\n",
    "\n",
    "How to Use? \n",
    "\"\"\"\n",
    "\n",
    "for keyword in onemg_dict.keys():\n",
    "    how_to_use_prompt = how_to_use_prompt_tmpl.format(keyword=keyword, source1=onemg_dict['NIKORAN 5MG BOTTLE OF 20 TABLETS\\n'].get('how_to_use', ''),\n",
    "                                                                            source2=apollo_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('directions', ''),\n",
    "                                                                            source3=netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('dir_of_use', ''))\n",
    "    \n",
    "    how_to_use = get_llm_response(how_to_use_prompt, 'Other Interactions')['response']\n",
    "    keywords_how_to_use[keyword] = how_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8843d7-0b4d-46d3-a3af-236dd8cafa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_uses = dict()\n",
    "uses_prompt_tmpl = \"\"\"\n",
    "We are writing a section 'Uses of Drug' on '{keyword}'.\n",
    "Using only the relevant information for the section from source1, source2 and source3 write in detail on the section.\n",
    "Stick to the information provided and facts as this might have legal issues. Use simple language, easy english, be descriptive and reword to make best for SEO and to avoid plagarism.\n",
    "\n",
    "Source1:\n",
    "{source1}\n",
    "\n",
    "Source2:\n",
    "{source2}\n",
    "\n",
    "Source3:\n",
    "{source3}\n",
    "\n",
    "Uses of Drug:\n",
    "\"\"\"\n",
    "for keyword in onemg_dict.keys():\n",
    "    uses_prompt = uses_prompt_tmpl.format(keyword=keyword, source1=onemg_dict['NIKORAN 5MG BOTTLE OF 20 TABLETS\\n'].get('drug_uses', ''),\n",
    "                                                                            source2=apollo_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('uses', ''),\n",
    "                                                                            source3=netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('uses_of', ''))\n",
    "    \n",
    "    uses_text = get_llm_response(uses_prompt, 'Other Interactions')['response']\n",
    "    keyword_uses[keyword] = uses_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad80221-c12a-4cb2-a800-c7f7e0b149ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_benefits = dict()\n",
    "benefits_prompt_tmpl = \"\"\"\n",
    "We are writing a section 'Benefits of Drug' on '{keyword}'.\n",
    "Using only the relevant information for the section from source1, source2 and source3 write in detail on the section.\n",
    "Stick to the information provided and facts as this might have legal issues. Use simple language, easy english, be descriptive and reword to make best for SEO and to avoid plagarism.\n",
    "\n",
    "Source1:\n",
    "{source1}\n",
    "\n",
    "Source2:\n",
    "{source2}\n",
    "\n",
    "\n",
    "Benefits of Drug:\n",
    "\"\"\"\n",
    "for keyword in onemg_dict.keys():\n",
    "    benefits_prompt = benefits_prompt_tmpl.format(keyword=keyword, source1=onemg_dict['NIKORAN 5MG BOTTLE OF 20 TABLETS\\n'].get('drug_benefits', ''),\n",
    "                                                                            source2=apollo_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('benefits', ''))\n",
    "    \n",
    "    benefits_text = get_llm_response(benefits_prompt, 'Other Interactions')['response']\n",
    "    keyword_benefits[keyword] = benefits_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859e33e-8068-4a32-93e6-c0115825e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_side_effects = dict()\n",
    "side_effets_prompt_tmpl = \"\"\"\n",
    "We are writing a section 'Side Effects of Drug' on '{keyword}'.\n",
    "Using only the relevant information for the section from source1, source2 and source3 write in detail on the section.\n",
    "Stick to the information provided and facts as this might have legal issues. Use simple language, easy english, be descriptive and reword to make best for SEO and to avoid plagarism.\n",
    "\n",
    "Source1:\n",
    "{source1}\n",
    "\n",
    "Source2:\n",
    "{source2}\n",
    "\n",
    "Source3:\n",
    "{source3}\n",
    "\n",
    "Side Effets of Drug:\n",
    "\"\"\"\n",
    "for keyword in onemg_dict.keys():\n",
    "    side_effets_prompt = side_effets_prompt_tmpl.format(keyword=keyword, source1=onemg_dict['NIKORAN 5MG BOTTLE OF 20 TABLETS\\n'].get('side_effects_list', ''), \n",
    "                                                        source2=apollo_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('side_effects',''), \n",
    "                                                        source3= netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('uncommon_text', '') + \n",
    "                                                        netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('common_text', '') +\n",
    "                                                        netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('rare_text', '') )\n",
    "    \n",
    "    side_effets_text = get_llm_response(side_effets_prompt, 'Other Interactions')['response']\n",
    "    keyword_side_effects[keyword] = side_effets_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df63f4-1271-4867-bb5a-db7e95687241",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_about = dict()\n",
    "about_product_prompt_tmpl = \"\"\"\n",
    "We are writing a section 'About Drug' on '{keyword}'.\n",
    "Using only the relevant information for the section from source1, source2 and source3 write in detail on the section.\n",
    "Stick to the information provided and facts as this might have legal issues. Use simple language, easy english, be descriptive and reword to make best for SEO and to avoid plagarism.\n",
    "\n",
    "Source1:\n",
    "{source1}\n",
    "\n",
    "Source2:\n",
    "{source2}\n",
    "\n",
    "\n",
    "About Drug:\n",
    "\"\"\"\n",
    "\n",
    "for keyword in onemg_dict.keys():\n",
    "    about_product_prompt = about_product_prompt_tmpl.format(keyword=keyword, source1=onemg_dict['NIKORAN 5MG BOTTLE OF 20 TABLETS\\n'].get('product_info', ''), \n",
    "                                                        source2=apollo_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('about',''), \n",
    "                                                        source3= netmeds_dict.get('NIKORAN 5MG BOTTLE OF 20 TABLETS\\n', {}).get('introduction', ''))\n",
    "    \n",
    "    about_product_text = get_llm_response(about_product_prompt, 'Other Interactions')['response']\n",
    "    keywords_about[keyword] = about_product_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ffeb7-ef5f-40bb-b772-85f42eba912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "about_product_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dafff8-ce2b-4aae-aa34-6e9e46563848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
